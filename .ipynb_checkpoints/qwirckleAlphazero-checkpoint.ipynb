{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lglw-LkAKOle"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XGpK6EopYBLq"
   },
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "69X_-qPkKOlh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "global epoch\n",
    "epoch = 0\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('werkzeug')\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BExJk30EKOli"
   },
   "outputs": [],
   "source": [
    "def get_next_state(board, player, action):\n",
    "    nextBoard = np.copy(board)\n",
    "    lign = 0\n",
    "    while nextBoard[lign][action] != 0 and sum(\n",
    "            (x != 0) for x in nextBoard.transpose().flatten()) < 42:\n",
    "        lign = (lign + 1) % 6\n",
    "    nextBoard[lign][action] = player\n",
    "\n",
    "    # Return the new game, but\n",
    "    # change the perspective of the game with negative\n",
    "    return nextBoard, -player\n",
    "\n",
    "\n",
    "def has_legal_moves(board):\n",
    "    for colonne in range(7):\n",
    "        if not colonnepleine(board, colonne) and sum(\n",
    "                (x != 0) for x in board.transpose().flatten()) < 42:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_valid_moves(board):\n",
    "    # All moves are invalid by default\n",
    "    valid_moves = [0] * 7\n",
    "\n",
    "    for colonne in range(7):\n",
    "        if not colonnepleine(board, colonne) and sum(\n",
    "                (x != 0) for x in board.transpose().flatten()) < 42:\n",
    "            valid_moves[colonne] = 1\n",
    "\n",
    "    return valid_moves\n",
    "\n",
    "\n",
    "def get_reward_for_player(board, player):\n",
    "    # return None if not ended, 1 if player 1 wins, -1 if player 1 lost\n",
    "\n",
    "    if colWin(board) or ligneWin(board) or diagRigthToLeftWin(board) or diagLeftToRightWin(board):\n",
    "        if winner == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    # if has_legal_moves(board):\n",
    "    #     return None\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_canonical_board(board, player):\n",
    "    return player * board\n",
    "\n",
    "\n",
    "def ucb_score(parent, child):\n",
    "    \"\"\"\n",
    "    The score for an action that would transition between the parent and child.\n",
    "    \"\"\"\n",
    "    prior_score = child.prior * math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
    "    if (child.visit_count > 0) and (child.prior > 0):\n",
    "        # The value of the child is from the perspective of the opposing player\n",
    "        value_score = -child.value()\n",
    "    else:\n",
    "        value_score = 0\n",
    "\n",
    "    return value_score + prior_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i5IcroHfKOlk"
   },
   "outputs": [],
   "source": [
    "def add_dirichlet_noise(child_priors):\n",
    "        colonnes = torch.sort(child_priors, descending=True)\n",
    "        action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "        action_idxs = action2rotation[colonnes.indices[0][0]]\n",
    "        valid_child_priors = child_priors[0][action_idxs]  # select only legal moves entries in child_priors array\n",
    "        valid_child_priors = 0.75 * valid_child_priors.cpu().detach().numpy() + 0.25 * np.random.dirichlet(\n",
    "            np.zeros([len(child_priors[0])], dtype=np.float32) + 192)\n",
    "        child_priors = torch.tensor([valid_child_priors], dtype=torch.float32)\n",
    "        return (child_priors)\n",
    "def convert_grid(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 1):\n",
    "                gridnorme[i][j] = -1\n",
    "            elif (grid[i][j] == 2):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] =0\n",
    "\n",
    "\n",
    "def convert_zero(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 0):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] =0\n",
    "def convert_one(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 1):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] = 0\n",
    "def convert_neg_one(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == -1):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-61Hi3drKOlk"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, prior, to_play):\n",
    "        self.visit_count = 0\n",
    "        self.to_play = to_play\n",
    "        self.prior = prior\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.state = None\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def select_child(self):\n",
    "        \"\"\"\n",
    "        Select the child with the highest UCB score.\n",
    "        \"\"\"\n",
    "        best_score = -np.inf\n",
    "        best_action = -1\n",
    "        best_child = None\n",
    "\n",
    "        for action, child in self.children.items():\n",
    "            score = ucb_score(self, child)\n",
    "            if not colonnepleine(self.state, action):\n",
    "                if score> best_score:\n",
    "                    best_score = score\n",
    "                    best_action = action\n",
    "                    best_child = child\n",
    "\n",
    "        return best_action, best_child\n",
    "\n",
    "    def expand(self, state, to_play, action_probs):\n",
    "        \"\"\"\n",
    "        We expand a node and keep track of the prior policy probability given by neural network\n",
    "        \"\"\"\n",
    "        self.to_play = to_play\n",
    "        self.state = state\n",
    "        for i in range(len(action_probs[0])):\n",
    "          if action_probs[0][i].data in torch.topk(action_probs[0], 5).values and colonneCouldWin(self.state, i):\n",
    "            self.children[i] = Node(prior=action_probs[0][i].item(), to_play=self.to_play * -1)\n",
    "          else:\n",
    "            self.children[i] = Node(prior=0, to_play=self.to_play * -1)\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Debugger pretty print node info\n",
    "        \"\"\"\n",
    "        prior = \"{0:.2f}\".format(self.prior)\n",
    "        return \"{} Prior: {} Count: {} Value: {}\".format(self.state.__str__(), prior, self.visit_count, self.value())\n",
    "                                                         \n",
    "class MCTS:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "          gridnormeOne = np.zeros(shape=(6, 7))\n",
    "          gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "          gridnormeZero = np.zeros(shape=(6, 7))\n",
    "          root = Node(0, to_play)\n",
    "          convert_zero(state, gridnormeZero)\n",
    "          convert_one(state, gridnormeOne)\n",
    "          convert_neg_one(state, gridnormenegOne)\n",
    "          gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "          action_probs, value = cnn(statesignal)\n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          for i in range(777):\n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  convert_zero(next_state, gridnormeZero)\n",
    "                  convert_one(next_state, gridnormeOne)\n",
    "                  convert_neg_one(next_state, gridnormenegOne)\n",
    "                  gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root\n",
    "\n",
    "class MCTS_iter:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "          gridnormeOne = np.zeros(shape=(6, 7))\n",
    "          gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "          gridnormeZero = np.zeros(shape=(6, 7))\n",
    "          root = Node(0, to_play)\n",
    "          convert_zero(state, gridnormeZero)\n",
    "          convert_one(state, gridnormeOne)\n",
    "          convert_neg_one(state, gridnormenegOne)\n",
    "          gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "          action_probs, value = cnn_iter1(statesignal)\n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          for i in range(777):\n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  convert_zero(next_state, gridnormeZero)\n",
    "                  convert_one(next_state, gridnormeOne)\n",
    "                  convert_neg_one(next_state, gridnormenegOne)\n",
    "                  gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn_iter1(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "\n",
    "\n",
    "# Making the body\n",
    "def colonnepleine(state, colonne):\n",
    "    grid = state.copy()\n",
    "    grid = grid.transpose()\n",
    "    plein = sum((x == 0) for x in grid[colonne]) == 0\n",
    "    return plein\n",
    "\n",
    "def colonneCouldWin(state, colonne):\n",
    "    grid = state.copy()\n",
    "    grid = grid.transpose()\n",
    "    notWin = (grid[colonne][3] == -1 and  grid[colonne][4] == 1) or (grid[colonne][3] == 1 and  grid[colonne][4] == -1)\n",
    "    return not notWin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = 7\n",
    "       # self.conv1 = nn.Conv2d(3, 1024, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn1 = nn.BatchNorm2d(1024).cuda()\n",
    "        #self.conv2 = nn.Conv2d(1024, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn2 = nn.BatchNorm2d(2048).cuda()\n",
    "        #self.conv3 = nn.Conv2d(2048, 4096, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn3 = nn.BatchNorm2d(4096).cuda()\n",
    "        #self.conv4 = nn.Conv2d(4096, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn4 = nn.BatchNorm2d(2048).cuda()\n",
    "        #self.conv5 = nn.Conv2d(2048, 512, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn5 = nn.BatchNorm2d(512).cuda()\n",
    "        self.conv1 = nn.Conv2d(3, 1024, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\n",
    "        self.conv2 = nn.Conv2d(1024, 2048, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(2048)\n",
    "        self.conv3 = nn.Conv2d(2048, 4096, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(4096)\n",
    "        self.conv4 = nn.Conv2d(4096, 2048, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(2048)\n",
    "        self.conv5 = nn.Conv2d(2048, 512, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.view(-1, 3, 6, 7)  # batch_size x channels x board_x x board_y\n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        s = F.relu(self.bn2(self.conv2(s)))\n",
    "        s = F.relu(self.bn3(self.conv3(s)))\n",
    "        s = F.relu(self.bn4(self.conv4(s)))\n",
    "        s = F.relu(self.bn5(self.conv5(s)))\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=512, planes=512, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "        #                       padding=1, bias=False).cuda()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        #self.bn1 = nn.BatchNorm2d(planes).cuda()\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        #self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "        #                       padding=1, bias=False).cuda()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        #self.bn2 = nn.BatchNorm2d(planes).cuda()\n",
    "        #self.drp = nn.Dropout(0.3).cuda()\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.drp = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.drp(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.bn2(out))\n",
    "        out = self.drp(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    # shape=6*7*32\n",
    "    shape = 1024\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.shape, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.drp = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(512, 7)\n",
    "\n",
    "    def forward(self, s):\n",
    "        v = s.view(-1, self.shape)  # batch_size X channel X height X width\n",
    "        v = self.drp(F.relu(self.fc1(v)))\n",
    "        v = torch.tanh(self.fc2(v))\n",
    "\n",
    "\n",
    "        p = s.view(-1, self.shape)\n",
    "        p = self.drp(F.relu(self.fc1(p)))\n",
    "        p = self.fc(p)\n",
    "        p = self.logsoftmax(p).exp()\n",
    "        return p, v\n",
    "\n",
    "\n",
    "class ConnectNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConnectNet, self).__init__()\n",
    "        #self.conv = ConvBlock().cuda()\n",
    "        self.conv = ConvBlock()\n",
    "        for block in range(30):\n",
    "            #setattr(self, \"res_%i\" % block, ResBlock().cuda())\n",
    "            setattr(self, \"res_%i\" % block, ResBlock())\n",
    "        self.outblock = OutBlock()\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(30):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights of layers using Kaiming Normal (He et al.) as argument of \"Apply\" function of\n",
    "        \"nn.Module\"\n",
    "        :param m: Layer to initialize\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if isinstance(self.conv.conv1, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv1.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv1.bias)\n",
    "        if isinstance(self.conv.bn1, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn1.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn1.bias.data, 0)\n",
    "        if isinstance(self.conv.conv2, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv2.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv2.bias)\n",
    "        if isinstance(self.conv.bn2, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn2.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn2.bias.data, 0)\n",
    "        if isinstance(self.conv.conv3, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv3.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv3.bias)\n",
    "        if isinstance(self.conv.bn3, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn3.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn3.bias.data, 0)\n",
    "        if isinstance(self.conv.conv4, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv4.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv4.bias)\n",
    "        if isinstance(self.conv.bn4, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn4.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn4.bias.data, 0)\n",
    "        if isinstance(self.conv.conv5, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv5.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv5.bias)\n",
    "        if isinstance(self.conv.bn5, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn5.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn5.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjlWf12-KOlt"
   },
   "outputs": [],
   "source": [
    "#cnn = ConnectNet().to(cuda0)\n",
    "cnn = ConnectNet()\n",
    "cnn.init_weights()\n",
    "#cnn_iter1 = ConnectNet().to(cuda0)\n",
    "cnn_iter1 = ConnectNet()\n",
    "cnn_iter1.init_weights()\n",
    "n_step = 0\n",
    "\n",
    "Step = namedtuple('Step', ['state', 'action', 'reward'])\n",
    "from dataclasses import dataclass\n",
    "\n",
    "mcts = MCTS()\n",
    "mcts_iter=MCTS_iter()\n",
    "@dataclass\n",
    "class Step:\n",
    "    state: []\n",
    "    action: []\n",
    "    reward: int = 0\n",
    "\n",
    "\n",
    "global memory\n",
    "\n",
    "global rewards\n",
    "rewards = []\n",
    "\n",
    "lossreward = nn.MSELoss()\n",
    "# lossreward = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.SGD(cnn.parameters(),lr=0.01,momentum=0.9,weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0000001)\n",
    "reward = 0.0\n",
    "global gridnorme\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def treeSearch(batch):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    values = []\n",
    "    for series in batch:\n",
    "        inputs.append(series.state)\n",
    "        targets.append(series.action)\n",
    "        values.append(series.reward)\n",
    "    return torch.tensor([t.numpy() for t in inputs], dtype=torch.float), torch.tensor([t.numpy() for t in targets],\n",
    "                                                                                      dtype=torch.float), torch.tensor(\n",
    "        [t.numpy() for t in values], dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_batch(batch_size):  # creates an iterator that returns random batches\n",
    "    ofs = 0\n",
    "    vals = list(memory)\n",
    "    np.random.shuffle(vals)\n",
    "    while (ofs + 1) * batch_size <= len(memory):\n",
    "        yield vals[ofs * batch_size:(ofs + 1) * batch_size]\n",
    "        ofs += 1\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "def contains(subseq, inseq):\n",
    "    return any(inseq[pos:pos + len(subseq)] == subseq for pos in range(0, len(inseq) - len(subseq) + 1))\n",
    "\n",
    "\n",
    "winner = 0\n",
    "\n",
    "\n",
    "def ligneWin(gridnorme):\n",
    "    global winner\n",
    "    expected = False\n",
    "    for lign in gridnorme:\n",
    "        if contains([1, 1, 1, 1], lign.tolist()):\n",
    "            winner = 1\n",
    "        if contains([-1, -1, -1, -1], lign.tolist()):\n",
    "            winner = -1\n",
    "        expected = expected or contains([1, 1, 1, 1], lign.tolist()) or contains([-1, -1, -1, -1], lign.tolist())\n",
    "    return expected\n",
    "\n",
    "\n",
    "def colWin(gridnorme):\n",
    "    return ligneWin(gridnorme.transpose())\n",
    "\n",
    "\n",
    "def diagLeftToRightWin(gridnorme):\n",
    "    griddiag = np.zeros(shape=(7, 6))\n",
    "    griddiag[0] = [gridnorme[0][3], gridnorme[1][4], gridnorme[2][5], gridnorme[3][6], 0, 0]\n",
    "    griddiag[1] = [gridnorme[0][2], gridnorme[1][3], gridnorme[2][4], gridnorme[3][5], gridnorme[4][6], 0]\n",
    "    griddiag[2] = [gridnorme[0][1], gridnorme[1][2], gridnorme[2][3], gridnorme[3][4], gridnorme[4][5], gridnorme[5][6]]\n",
    "    griddiag[3] = [gridnorme[0][0], gridnorme[1][1], gridnorme[2][2], gridnorme[3][3], gridnorme[4][4], gridnorme[5][5]]\n",
    "    griddiag[4] = [gridnorme[1][0], gridnorme[2][1], gridnorme[3][2], gridnorme[4][3], gridnorme[5][4], 0]\n",
    "    griddiag[5] = [gridnorme[2][0], gridnorme[2][1], gridnorme[2][2], gridnorme[2][3], 0, 0]\n",
    "    return ligneWin(griddiag)\n",
    "\n",
    "\n",
    "def diagRigthToLeftWin(gridnorme):\n",
    "    griddiag = np.zeros(shape=(7, 6))\n",
    "    griddiag[0] = [gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3], 0, 0]\n",
    "    griddiag[1] = [gridnorme[4][0], gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3], 0]\n",
    "    griddiag[2] = [gridnorme[5][0], gridnorme[4][0], gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3]]\n",
    "    griddiag[3] = [gridnorme[5][1], gridnorme[4][2], gridnorme[3][3], gridnorme[2][4], gridnorme[1][5], gridnorme[0][6]]\n",
    "    griddiag[4] = [gridnorme[4][1], gridnorme[3][2], gridnorme[2][3], gridnorme[1][4], gridnorme[0][5], 0]\n",
    "    griddiag[5] = [gridnorme[3][1], gridnorme[2][2], gridnorme[1][3], gridnorme[0][4], 0, 0]\n",
    "\n",
    "    return ligneWin(griddiag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "memory = deque()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "maxWin = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uVe3O-jKOlu"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wWGSASDKOlu"
   },
   "outputs": [],
   "source": [
    "def localtest():  \n",
    "  global gridnorme, colred, epoch, memory, winner,maxWin\n",
    "  print(\"test ok: max=\", maxWin)\n",
    "  blueWinner = 0\n",
    "  redWinner = 0\n",
    "  equality = 0\n",
    "  # with torch.no_grad():\n",
    "  def playerCol():\n",
    "      bestcol = random.randrange(7)\n",
    "      j = 0\n",
    "      while colonnepleine(gridnorme, bestcol) and sum(\n",
    "              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "          j = (j + 1) % 7\n",
    "          bestcol = random.randrange(7)\n",
    "      grid = gridnorme.transpose().copy()\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, -1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, -1, -1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      return bestcol;\n",
    "  \n",
    "  def playerRandom():\n",
    "      \n",
    "      bestcol = random.randrange(7)\n",
    "      j = 0\n",
    "      while colonnepleine(gridnorme, bestcol) and sum(\n",
    "              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "          j = (j + 1) % 7\n",
    "          bestcol = random.randrange(7)\n",
    "      return bestcol;\n",
    "\n",
    "  for p in range(0, 100):\n",
    "      first = False\n",
    "      gridnorme = np.zeros(shape=(6, 7))\n",
    "\n",
    "      for i in range(0, 42):\n",
    "\n",
    "          if first:\n",
    "\n",
    "              if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                      diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "                      \n",
    "                  actions = mcts.run(gridnorme, 1)\n",
    "                  # root = MonteCarloTreeSearchNode(state=gridnorme)\n",
    "                  # selected_node = root.best_action()\n",
    "                  actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                          dtype=torch.float32)\n",
    "                  actions /= torch.sum(actions)\n",
    "\n",
    "                  colonnes = torch.sort(actions, descending=True)\n",
    "                  action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                  colonne = action2rotation[colonnes.indices[0]]\n",
    "                  j = 0\n",
    "                  while colonnepleine(gridnorme, colonne) and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      j = (j + 1) % len(colonnes.indices)\n",
    "                      colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                  colonne = action2rotation[colonne]\n",
    "                  lign = 0\n",
    "                  while gridnorme[lign][colonne] != 0 and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      lign = (lign + 1) % 6\n",
    "                  gridnorme[lign][colonne] = 1\n",
    "                  first = not first\n",
    "              else:\n",
    "                  break\n",
    "          else:\n",
    "\n",
    "              if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                      diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "                  actions = mcts_iter.run(gridnorme, -1)\n",
    "                  # root = MonteCarloTreeSearchNode(state=gridnorme)\n",
    "                  # selected_node = root.best_action()\n",
    "                  actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                          dtype=torch.float32)\n",
    "                  actions /= torch.sum(actions)\n",
    "\n",
    "                  colonnes = torch.sort(actions, descending=True)\n",
    "                  action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                  colonne = action2rotation[colonnes.indices[0]]\n",
    "                  j = 0\n",
    "                  while colonnepleine(gridnorme, colonne) and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      j = (j + 1) % len(colonnes.indices)\n",
    "                      colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                  colonne = action2rotation[colonne]\n",
    "                  lign = 0\n",
    "                  while gridnorme[lign][colonne] != 0 and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      lign = (lign + 1) % 6\n",
    "                  gridnorme[lign][colonne] = -1\n",
    "                  first = not first\n",
    "              else:\n",
    "                  break\n",
    "        \n",
    "\n",
    "      if winner == 1:\n",
    "        blueWinner += 1\n",
    "        winner = 0\n",
    "      elif winner == -1:\n",
    "        winner = 0\n",
    "        redWinner += 1\n",
    "      else:\n",
    "        equality += 1\n",
    "\n",
    "\n",
    "    \n",
    "       \n",
    "\n",
    "  return blueWinner, redWinner, equality\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojVcbLdhyqCP"
   },
   "outputs": [],
   "source": [
    "def moyenne_glissante(valeurs, intervalle):\n",
    "    indice_debut = (intervalle - 1) // 2\n",
    "    liste_moyennes = [sum(valeurs[i - indice_debut:i + indice_debut + 1]) / intervalle for i in range(indice_debut, len(valeurs) - indice_debut)]\n",
    "    return liste_moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLQTyqaf-EG9"
   },
   "outputs": [],
   "source": [
    "class AlphaLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_value, value, y_policy, policy):\n",
    "        value_error = (value - y_value) ** 2\n",
    "        policy_error = torch.sum((-policy *\n",
    "                                  (1e-8 + y_policy.float()).float().log()), 1)\n",
    "        total_error = (value_error.view(-1).float() + policy_error).mean()\n",
    "        return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PwtFhU9byqCc",
    "outputId": "dbbd6542-dca0-489b-a0fd-2d49853c9b7b"
   },
   "outputs": [],
   "source": [
    "global moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "alphaloss = AlphaLoss()\n",
    "BATCH_SIZE=64\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.figure()\n",
    "from IPython.display import clear_output\n",
    "moyenneWinBlue=[]\n",
    "runningloss = []\n",
    "acurracy=[]\n",
    "def localtrain():\n",
    "    global maxWin,moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(0, 20):\n",
    "\n",
    "\n",
    "      batch_idx = 0\n",
    "      \n",
    "      pi_losses = []\n",
    "      v_losses = []\n",
    "\n",
    "      while batch_idx < int(len(memory) / BATCH_SIZE):\n",
    "\n",
    "        sample_ids = np.random.randint(0, len(memory), BATCH_SIZE)\n",
    "        boards, pis, vs = list(zip(*[(memory[i]) for i in sample_ids]))\n",
    "        gridnormeOne = np.zeros(shape=(6, 7))\n",
    "        gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "        gridnormeZero = np.zeros(shape=(6, 7))\n",
    "        boards = torch.FloatTensor(boards).cuda()\n",
    "\n",
    "        boardsAll=[]\n",
    "        for board in boards:\n",
    "            convert_zero(board,gridnormeZero)\n",
    "            convert_one(board, gridnormeOne)\n",
    "            convert_neg_one(board, gridnormenegOne)\n",
    "            gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "            last_signal = torch.FloatTensor(gridAll).cuda()\n",
    "            last_signal = last_signal.reshape(3, 6, 7)\n",
    "            boardsAll.append(last_signal)\n",
    "        pisAll = []\n",
    "        for policy in pis:\n",
    "            policy = torch.tensor(policy, dtype=torch.float32).cuda()\n",
    "            pisAll.append(policy)\n",
    "        vsAll = []\n",
    "        for value in vs:\n",
    "            value = torch.tensor(value, dtype=torch.float32).cuda()\n",
    "            vsAll.append(value)\n",
    "\n",
    "        statesignal = torch.FloatTensor([t.detach().cpu().numpy() for t in boardsAll]).cuda()\n",
    "\n",
    "        target_pis =torch.FloatTensor([t.cpu().numpy() for t in pisAll]).cuda()\n",
    "        target_vs = torch.FloatTensor(vsAll).cuda().reshape(BATCH_SIZE,1)\n",
    "          \n",
    "          \n",
    "        \n",
    "        out_pi, out_v = cnn(statesignal)\n",
    "        total_error=alphaloss(out_v,target_vs,out_pi,target_pis)\n",
    "        optimizer.zero_grad()\n",
    "        pi_losses.append(float(total_error))\n",
    "        total_error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_idx += 1\n",
    "    print('Policy Loss:{:.2f}'.format(np.mean(pi_losses)))\n",
    "    \n",
    "    \n",
    "    runningloss.append(np.mean(pi_losses))        \n",
    "    \n",
    "    clear_output(wait=True)     \n",
    "    pal = sns.dark_palette('purple',2)\n",
    "    ax = sns.lineplot(data=runningloss,palette=pal, color='red',  alpha=.5, linewidth=2)\n",
    "    ax.legend(['loss'])\n",
    "    # Customise some display properties\n",
    "    ax.set_title('winblueloss')\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set(ylim=(0, max(runningloss)))\n",
    "    # Ask Matplotlib to show it\n",
    "    plt.show()\n",
    "    savebraintrain()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxSE6qe5KOlv"
   },
   "outputs": [],
   "source": [
    "def local(num_game):\n",
    "    \n",
    "\n",
    "    global gridnorme, colred, epoch, memory, history, n_steps, maxWin\n",
    "    \n",
    "\n",
    "    interval = []\n",
    "\n",
    "    \n",
    "    for h in range(0, num_game):\n",
    "        start_time = time.time()\n",
    "        n_steps = []\n",
    "        gridnorme = np.zeros(shape=(6, 7))\n",
    "        first = random.choice([True, False])\n",
    "        \n",
    "        for i in range(0, 42):\n",
    "            \n",
    "\n",
    "           \n",
    "\n",
    "            if first:\n",
    "                \n",
    "\n",
    "                if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                        diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "\n",
    "                      actions = mcts.run(gridnorme, -1)\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32).cuda()\n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = -1\n",
    "                      first = not first\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                        diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "\n",
    "                      \n",
    "                      \n",
    "\n",
    "                      actions = mcts.run(gridnorme, 1)\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32).cuda()\n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = 1\n",
    "                      first = not first\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        n_steps.append([deepcopy(gridnorme), [0, 0, 0, 0, 0, 0, 0], 0])\n",
    "        if winner == 1:\n",
    "\n",
    "            reward=-1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "        elif winner == -1:\n",
    "\n",
    "            reward = 1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "\n",
    "\n",
    "        else:\n",
    "            for rew in range(0, len(n_steps)):\n",
    "                n_steps[rew][2] = 0\n",
    "\n",
    "        memory.extend(n_steps)\n",
    "\n",
    "        n_steps = []\n",
    "\n",
    "        \n",
    "            \n",
    "        interval.append(time.time() - start_time)\n",
    "        if h > 5:\n",
    "            localtrain()\n",
    "        print('Total time in seconde:{:.2f}  '.format(np.mean(interval)),' ',h)\n",
    "        if h%10==0:\n",
    "          savebrain1()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqenSZ-hKOlw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import csv\n",
    "def savebrain1():\n",
    "    global savefile\n",
    "    global cnn, optimizer, cnnred\n",
    "    \n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    checkpoint = {'model': cnn,\n",
    "                  'state_dict': cnn.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, 'bestrandom.pth')\n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    \n",
    "def savebraintrain():\n",
    "    global savefile\n",
    "    global runningloss\n",
    "    \n",
    "\n",
    "    with open('loss_2000.csv', mode='w') as loss_file:\n",
    "        blue_writer = csv.writer(loss_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        blue_writer.writerow(runningloss)\n",
    "\n",
    "    print(\"=> saving moyenne... \",runningloss[len(runningloss)-1])\n",
    "        \n",
    "def loadbrain2():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('best_iter200.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "        checkpoint = torch.load('best_iter200.pth', map_location=cuda0)\n",
    "        cnn_iter1.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "        \n",
    "def loadcsv():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred,runningloss\n",
    "    \n",
    "    if os.path.isfile('loss_2000.csv'):\n",
    "\n",
    "        with open('loss_2000.csv', newline='') as f:\n",
    "            reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "            runningloss = list(reader)[0]\n",
    "\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "\n",
    "def loadbrain1():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('bestrandom.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "        checkpoint = torch.load('bestrandom.pth', map_location=cuda0)\n",
    "        cnn.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "      \n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YqafRVhUMnF",
    "outputId": "958f3e22-0d52-491b-ea89-94e1e3f04282"
   },
   "outputs": [],
   "source": [
    "\n",
    "loadcsv()\n",
    "\n",
    "loadbrain1()\n",
    "#loadbrain2()\n",
    "# savebrain1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "d6BmGH9pyqCg",
    "outputId": "3dfca9ef-bc68-4aba-9efa-b65c17e7711e"
   },
   "outputs": [],
   "source": [
    "local(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RaHHwNF9jCD"
   },
   "outputs": [],
   "source": [
    "savebrain1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runningloss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Connect4_alpha_zero.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "hide_input": false,
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
