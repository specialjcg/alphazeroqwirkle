{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lglw-LkAKOle"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XGpK6EopYBLq"
   },
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "69X_-qPkKOlh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "global epoch\n",
    "epoch = 0\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('werkzeug')\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BExJk30EKOli"
   },
   "outputs": [],
   "source": [
    "def get_next_state(board, player, action):\n",
    "    nextBoard = np.copy(board)\n",
    "    lign = 0\n",
    "    while nextBoard[lign][action] != 0 and sum(\n",
    "            (x != 0) for x in nextBoard.transpose().flatten()) < 42:\n",
    "        lign = (lign + 1) % 6\n",
    "    nextBoard[lign][action] = player\n",
    "\n",
    "    # Return the new game, but\n",
    "    # change the perspective of the game with negative\n",
    "    return nextBoard, -player\n",
    "\n",
    "\n",
    "def has_legal_moves(board):\n",
    "    for colonne in range(7):\n",
    "        if not colonnepleine(board, colonne) and sum(\n",
    "                (x != 0) for x in board.transpose().flatten()) < 42:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_valid_moves(board):\n",
    "    # All moves are invalid by default\n",
    "    valid_moves = [0] * 7\n",
    "\n",
    "    for colonne in range(7):\n",
    "        if not colonnepleine(board, colonne) and sum(\n",
    "                (x != 0) for x in board.transpose().flatten()) < 42:\n",
    "            valid_moves[colonne] = 1\n",
    "\n",
    "    return valid_moves\n",
    "\n",
    "\n",
    "def get_reward_for_player(board, player):\n",
    "    # return None if not ended, 1 if player 1 wins, -1 if player 1 lost\n",
    "\n",
    "    if colWin(board) or ligneWin(board) or diagRigthToLeftWin(board) or diagLeftToRightWin(board):\n",
    "        if winner == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    # if has_legal_moves(board):\n",
    "    #     return None\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_canonical_board(board, player):\n",
    "    return player * board\n",
    "\n",
    "\n",
    "def ucb_score(parent, child):\n",
    "    \"\"\"\n",
    "    The score for an action that would transition between the parent and child.\n",
    "    \"\"\"\n",
    "    prior_score = child.prior * math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
    "    if (child.visit_count > 0) and (child.prior > 0):\n",
    "        # The value of the child is from the perspective of the opposing player\n",
    "        value_score = -child.value()\n",
    "    else:\n",
    "        value_score = 0\n",
    "\n",
    "    return value_score + prior_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i5IcroHfKOlk"
   },
   "outputs": [],
   "source": [
    "def add_dirichlet_noise(child_priors):\n",
    "        colonnes = torch.sort(child_priors, descending=True)\n",
    "        action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "        action_idxs = action2rotation[colonnes.indices[0][0]]\n",
    "        valid_child_priors = child_priors[0][action_idxs]  # select only legal moves entries in child_priors array\n",
    "        valid_child_priors = 0.75 * valid_child_priors.cpu().detach().numpy() + 0.25 * np.random.dirichlet(\n",
    "            np.zeros([len(child_priors[0])], dtype=np.float32) + 192)\n",
    "        child_priors = torch.tensor([valid_child_priors], dtype=torch.float32)\n",
    "        return (child_priors)\n",
    "def convert_grid(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 1):\n",
    "                gridnorme[i][j] = -1\n",
    "            elif (grid[i][j] == 2):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] =0\n",
    "\n",
    "\n",
    "def convert_zero(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 0):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] =0\n",
    "def convert_one(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == 1):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] = 0\n",
    "def convert_neg_one(grid, gridnorme):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if (grid[i][j] == -1):\n",
    "                gridnorme[i][j] = 1\n",
    "            else:\n",
    "                gridnorme[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-61Hi3drKOlk"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, prior, to_play):\n",
    "        self.visit_count = 0\n",
    "        self.to_play = to_play\n",
    "        self.prior = prior\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.state = None\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def select_child(self):\n",
    "        \"\"\"\n",
    "        Select the child with the highest UCB score.\n",
    "        \"\"\"\n",
    "        best_score = -np.inf\n",
    "        best_action = -1\n",
    "        best_child = None\n",
    "\n",
    "        for action, child in self.children.items():\n",
    "            score = ucb_score(self, child)\n",
    "            if not colonnepleine(self.state, action):\n",
    "                if score> best_score:\n",
    "                    best_score = score\n",
    "                    best_action = action\n",
    "                    best_child = child\n",
    "\n",
    "        return best_action, best_child\n",
    "\n",
    "    def expand(self, state, to_play, action_probs):\n",
    "        \"\"\"\n",
    "        We expand a node and keep track of the prior policy probability given by neural network\n",
    "        \"\"\"\n",
    "        self.to_play = to_play\n",
    "        self.state = state\n",
    "        for i in range(len(action_probs[0])):\n",
    "          if action_probs[0][i].data in torch.topk(action_probs[0], 5).values and colonneCouldWin(self.state, i):\n",
    "            self.children[i] = Node(prior=action_probs[0][i].item(), to_play=self.to_play * -1)\n",
    "          else:\n",
    "            self.children[i] = Node(prior=0, to_play=self.to_play * -1)\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Debugger pretty print node info\n",
    "        \"\"\"\n",
    "        prior = \"{0:.2f}\".format(self.prior)\n",
    "        return \"{} Prior: {} Count: {} Value: {}\".format(self.state.__str__(), prior, self.visit_count, self.value())\n",
    "                                                         \n",
    "class MCTS:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "          gridnormeOne = np.zeros(shape=(6, 7))\n",
    "          gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "          gridnormeZero = np.zeros(shape=(6, 7))\n",
    "          root = Node(0, to_play)\n",
    "          convert_zero(state, gridnormeZero)\n",
    "          convert_one(state, gridnormeOne)\n",
    "          convert_neg_one(state, gridnormenegOne)\n",
    "          gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "          action_probs, value = cnn(statesignal)\n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          for i in range(777):\n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  convert_zero(next_state, gridnormeZero)\n",
    "                  convert_one(next_state, gridnormeOne)\n",
    "                  convert_neg_one(next_state, gridnormenegOne)\n",
    "                  gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root\n",
    "\n",
    "class MCTS_iter:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "          gridnormeOne = np.zeros(shape=(6, 7))\n",
    "          gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "          gridnormeZero = np.zeros(shape=(6, 7))\n",
    "          root = Node(0, to_play)\n",
    "          convert_zero(state, gridnormeZero)\n",
    "          convert_one(state, gridnormeOne)\n",
    "          convert_neg_one(state, gridnormenegOne)\n",
    "          gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "          action_probs, value = cnn_iter1(statesignal)\n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          for i in range(777):\n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  convert_zero(next_state, gridnormeZero)\n",
    "                  convert_one(next_state, gridnormeOne)\n",
    "                  convert_neg_one(next_state, gridnormenegOne)\n",
    "                  gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn_iter1(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()  # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "\n",
    "\n",
    "# Making the body\n",
    "def colonnepleine(state, colonne):\n",
    "    grid = state.copy()\n",
    "    grid = grid.transpose()\n",
    "    plein = sum((x == 0) for x in grid[colonne]) == 0\n",
    "    return plein\n",
    "\n",
    "def colonneCouldWin(state, colonne):\n",
    "    grid = state.copy()\n",
    "    grid = grid.transpose()\n",
    "    notWin = (grid[colonne][3] == -1 and  grid[colonne][4] == 1) or (grid[colonne][3] == 1 and  grid[colonne][4] == -1)\n",
    "    return not notWin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.action_size = 7\n",
    "#         self.conv1 = nn.Conv2d(3, 512, kernel_size=4, stride=1, padding=1).cuda()\n",
    "#         self.bn1 = nn.BatchNorm2d(512).cuda()\n",
    "#         self.conv2 = nn.Conv2d(512, 1024, kernel_size=4, stride=1, padding=1).cuda()\n",
    "#         self.bn2 = nn.BatchNorm2d(1024).cuda()\n",
    "#         self.conv3 = nn.Conv2d(1024, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "#         self.bn3 = nn.BatchNorm2d(2048).cuda()\n",
    "#         self.conv4 = nn.Conv2d(2048, 1024, kernel_size=4, stride=1, padding=1).cuda()\n",
    "#         self.bn4 = nn.BatchNorm2d(1024).cuda()\n",
    "#         self.conv5 = nn.Conv2d(1024, 512, kernel_size=4, stride=1, padding=1).cuda()\n",
    "#         self.bn5 = nn.BatchNorm2d(512).cuda()\n",
    "\n",
    "\n",
    "#     def forward(self, s):\n",
    "#         s = s.view(-1, 3, 6, 7)  # batch_size x channels x board_x x board_y\n",
    "#         s = F.relu(self.bn1(self.conv1(s)))\n",
    "#         s = F.relu(self.bn2(self.conv2(s)))\n",
    "#         s = F.relu(self.bn3(self.conv3(s)))\n",
    "#         s = F.relu(self.bn4(self.conv4(s)))\n",
    "#         s = F.relu(self.bn5(self.conv5(s)))\n",
    "\n",
    "#         return s\n",
    "\n",
    "\n",
    "# class ResBlock(nn.Module):\n",
    "#     def __init__(self, inplanes=512, planes=512, stride=1, downsample=None):\n",
    "#         super(ResBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "#                                padding=1, bias=False).cuda()\n",
    "#         self.bn1 = nn.BatchNorm2d(planes).cuda()\n",
    "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "#                                padding=1, bias=False).cuda()\n",
    "#         self.bn2 = nn.BatchNorm2d(planes).cuda()\n",
    "#         self.drp = nn.Dropout(0.3).cuda()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         out = self.conv1(x)\n",
    "#         out = F.relu(self.bn1(out))\n",
    "#         out = self.drp(out)\n",
    "#         out = self.conv2(out)\n",
    "#         out = F.relu(self.bn2(out))\n",
    "#         out = self.drp(out)\n",
    "#         out += residual\n",
    "#         out = F.relu(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "# class OutBlock(nn.Module):\n",
    "#     # shape=6*7*32\n",
    "#     shape = 1024\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(OutBlock, self).__init__()\n",
    "\n",
    "#         self.fc1 = nn.Linear(self.shape, 512)\n",
    "#         self.fc2 = nn.Linear(512, 1)\n",
    "#         self.drp = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "#         self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "#         self.fc = nn.Linear(512, 7)\n",
    "\n",
    "#     def forward(self, s):\n",
    "#         v = s.view(-1, self.shape)  # batch_size X channel X height X width\n",
    "#         v = self.drp(F.relu(self.fc1(v)))\n",
    "#         v = torch.tanh(self.fc2(v))\n",
    "\n",
    "\n",
    "#         p = s.view(-1, self.shape)\n",
    "#         p = self.drp(F.relu(self.fc1(p)))\n",
    "#         p = self.fc(p)\n",
    "#         p = self.logsoftmax(p).exp()\n",
    "#         return p, v\n",
    "\n",
    "\n",
    "# class ConnectNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConnectNet, self).__init__()\n",
    "#         self.conv = ConvBlock().cuda()\n",
    "#         for block in range(20):\n",
    "#             setattr(self, \"res_%i\" % block, ResBlock().cuda())\n",
    "#         self.outblock = OutBlock()\n",
    "\n",
    "#     def forward(self, s):\n",
    "#         s = self.conv(s)\n",
    "#         for block in range(20):\n",
    "#             s = getattr(self, \"res_%i\" % block)(s)\n",
    "#         s = self.outblock(s)\n",
    "#         return s\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         \"\"\"\n",
    "#         Initialize weights of layers using Kaiming Normal (He et al.) as argument of \"Apply\" function of\n",
    "#         \"nn.Module\"\n",
    "#         :param m: Layer to initialize\n",
    "#         :return: None\n",
    "#         \"\"\"\n",
    "#         if isinstance(self.conv.conv1, nn.Conv2d):\n",
    "#             torch.nn.init.xavier_uniform_(self.conv.conv1.weight)\n",
    "#             torch.nn.init.zeros_(self.conv.conv1.bias)\n",
    "#         if isinstance(self.conv.bn1, nn.BatchNorm2d):\n",
    "#             torch.nn.init.normal_(self.conv.bn1.weight.data, mean=1, std=0.02)\n",
    "#             torch.nn.init.constant_(self.conv.bn1.bias.data, 0)\n",
    "#         if isinstance(self.conv.conv2, nn.Conv2d):\n",
    "#             torch.nn.init.xavier_uniform_(self.conv.conv2.weight)\n",
    "#             torch.nn.init.zeros_(self.conv.conv2.bias)\n",
    "#         if isinstance(self.conv.bn2, nn.BatchNorm2d):\n",
    "#             torch.nn.init.normal_(self.conv.bn2.weight.data, mean=1, std=0.02)\n",
    "#             torch.nn.init.constant_(self.conv.bn2.bias.data, 0)\n",
    "#         if isinstance(self.conv.conv3, nn.Conv2d):\n",
    "#             torch.nn.init.xavier_uniform_(self.conv.conv3.weight)\n",
    "#             torch.nn.init.zeros_(self.conv.conv3.bias)\n",
    "#         if isinstance(self.conv.bn3, nn.BatchNorm2d):\n",
    "#             torch.nn.init.normal_(self.conv.bn3.weight.data, mean=1, std=0.02)\n",
    "#             torch.nn.init.constant_(self.conv.bn3.bias.data, 0)\n",
    "#         if isinstance(self.conv.conv4, nn.Conv2d):\n",
    "#             torch.nn.init.xavier_uniform_(self.conv.conv4.weight)\n",
    "#             torch.nn.init.zeros_(self.conv.conv4.bias)\n",
    "#         if isinstance(self.conv.bn4, nn.BatchNorm2d):\n",
    "#             torch.nn.init.normal_(self.conv.bn4.weight.data, mean=1, std=0.02)\n",
    "#             torch.nn.init.constant_(self.conv.bn4.bias.data, 0)\n",
    "#         if isinstance(self.conv.conv5, nn.Conv2d):\n",
    "#             torch.nn.init.xavier_uniform_(self.conv.conv5.weight)\n",
    "#             torch.nn.init.zeros_(self.conv.conv5.bias)\n",
    "#         if isinstance(self.conv.bn5, nn.BatchNorm2d):\n",
    "#             torch.nn.init.normal_(self.conv.bn5.weight.data, mean=1, std=0.02)\n",
    "#             torch.nn.init.constant_(self.conv.bn5.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = 7\n",
    "        self.conv1 = nn.Conv2d(3, 1024, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        self.bn1 = nn.BatchNorm2d(1024).cuda()\n",
    "        self.conv2 = nn.Conv2d(1024, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        self.bn2 = nn.BatchNorm2d(2048).cuda()\n",
    "        self.conv3 = nn.Conv2d(2048, 4096, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        self.bn3 = nn.BatchNorm2d(4096).cuda()\n",
    "        self.conv4 = nn.Conv2d(4096, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        self.bn4 = nn.BatchNorm2d(2048).cuda()\n",
    "        self.conv5 = nn.Conv2d(2048, 512, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        self.bn5 = nn.BatchNorm2d(512).cuda()\n",
    "\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.view(-1, 3, 6, 7)  # batch_size x channels x board_x x board_y\n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        s = F.relu(self.bn2(self.conv2(s)))\n",
    "        s = F.relu(self.bn3(self.conv3(s)))\n",
    "        s = F.relu(self.bn4(self.conv4(s)))\n",
    "        s = F.relu(self.bn5(self.conv5(s)))\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=512, planes=512, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False).cuda()\n",
    "        self.bn1 = nn.BatchNorm2d(planes).cuda()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False).cuda()\n",
    "        self.bn2 = nn.BatchNorm2d(planes).cuda()\n",
    "        self.drp = nn.Dropout(0.3).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.drp(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.bn2(out))\n",
    "        out = self.drp(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    # shape=6*7*32\n",
    "    shape = 1024\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.shape, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.drp = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(512, 7)\n",
    "\n",
    "    def forward(self, s):\n",
    "        v = s.view(-1, self.shape)  # batch_size X channel X height X width\n",
    "        v = self.drp(F.relu(self.fc1(v)))\n",
    "        v = torch.tanh(self.fc2(v))\n",
    "\n",
    "\n",
    "        p = s.view(-1, self.shape)\n",
    "        p = self.drp(F.relu(self.fc1(p)))\n",
    "        p = self.fc(p)\n",
    "        p = self.logsoftmax(p).exp()\n",
    "        return p, v\n",
    "\n",
    "\n",
    "class ConnectNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConnectNet, self).__init__()\n",
    "        self.conv = ConvBlock().cuda()\n",
    "        for block in range(30):\n",
    "            setattr(self, \"res_%i\" % block, ResBlock().cuda())\n",
    "        self.outblock = OutBlock()\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(30):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights of layers using Kaiming Normal (He et al.) as argument of \"Apply\" function of\n",
    "        \"nn.Module\"\n",
    "        :param m: Layer to initialize\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if isinstance(self.conv.conv1, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv1.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv1.bias)\n",
    "        if isinstance(self.conv.bn1, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn1.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn1.bias.data, 0)\n",
    "        if isinstance(self.conv.conv2, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv2.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv2.bias)\n",
    "        if isinstance(self.conv.bn2, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn2.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn2.bias.data, 0)\n",
    "        if isinstance(self.conv.conv3, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv3.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv3.bias)\n",
    "        if isinstance(self.conv.bn3, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn3.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn3.bias.data, 0)\n",
    "        if isinstance(self.conv.conv4, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv4.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv4.bias)\n",
    "        if isinstance(self.conv.bn4, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn4.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn4.bias.data, 0)\n",
    "        if isinstance(self.conv.conv5, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv5.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv5.bias)\n",
    "        if isinstance(self.conv.bn5, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn5.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn5.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VjlWf12-KOlt"
   },
   "outputs": [],
   "source": [
    "cnn = ConnectNet().to(cuda0)\n",
    "cnn.init_weights()\n",
    "cnn_iter1 = ConnectNet().to(cuda0)\n",
    "cnn_iter1.init_weights()\n",
    "n_step = 0\n",
    "\n",
    "Step = namedtuple('Step', ['state', 'action', 'reward'])\n",
    "from dataclasses import dataclass\n",
    "\n",
    "mcts = MCTS()\n",
    "mcts_iter=MCTS_iter()\n",
    "@dataclass\n",
    "class Step:\n",
    "    state: []\n",
    "    action: []\n",
    "    reward: int = 0\n",
    "\n",
    "\n",
    "global memory\n",
    "\n",
    "global rewards\n",
    "rewards = []\n",
    "\n",
    "lossreward = nn.MSELoss()\n",
    "# lossreward = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.SGD(cnn.parameters(),lr=0.01,momentum=0.9,weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0000001)\n",
    "reward = 0.0\n",
    "global gridnorme\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def treeSearch(batch):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    values = []\n",
    "    for series in batch:\n",
    "        inputs.append(series.state)\n",
    "        targets.append(series.action)\n",
    "        values.append(series.reward)\n",
    "    return torch.tensor([t.numpy() for t in inputs], dtype=torch.float), torch.tensor([t.numpy() for t in targets],\n",
    "                                                                                      dtype=torch.float), torch.tensor(\n",
    "        [t.numpy() for t in values], dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_batch(batch_size):  # creates an iterator that returns random batches\n",
    "    ofs = 0\n",
    "    vals = list(memory)\n",
    "    np.random.shuffle(vals)\n",
    "    while (ofs + 1) * batch_size <= len(memory):\n",
    "        yield vals[ofs * batch_size:(ofs + 1) * batch_size]\n",
    "        ofs += 1\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "def contains(subseq, inseq):\n",
    "    return any(inseq[pos:pos + len(subseq)] == subseq for pos in range(0, len(inseq) - len(subseq) + 1))\n",
    "\n",
    "\n",
    "winner = 0\n",
    "\n",
    "\n",
    "def ligneWin(gridnorme):\n",
    "    global winner\n",
    "    expected = False\n",
    "    for lign in gridnorme:\n",
    "        if contains([1, 1, 1, 1], lign.tolist()):\n",
    "            winner = 1\n",
    "        if contains([-1, -1, -1, -1], lign.tolist()):\n",
    "            winner = -1\n",
    "        expected = expected or contains([1, 1, 1, 1], lign.tolist()) or contains([-1, -1, -1, -1], lign.tolist())\n",
    "    return expected\n",
    "\n",
    "\n",
    "def colWin(gridnorme):\n",
    "    return ligneWin(gridnorme.transpose())\n",
    "\n",
    "\n",
    "def diagLeftToRightWin(gridnorme):\n",
    "    griddiag = np.zeros(shape=(7, 6))\n",
    "    griddiag[0] = [gridnorme[0][3], gridnorme[1][4], gridnorme[2][5], gridnorme[3][6], 0, 0]\n",
    "    griddiag[1] = [gridnorme[0][2], gridnorme[1][3], gridnorme[2][4], gridnorme[3][5], gridnorme[4][6], 0]\n",
    "    griddiag[2] = [gridnorme[0][1], gridnorme[1][2], gridnorme[2][3], gridnorme[3][4], gridnorme[4][5], gridnorme[5][6]]\n",
    "    griddiag[3] = [gridnorme[0][0], gridnorme[1][1], gridnorme[2][2], gridnorme[3][3], gridnorme[4][4], gridnorme[5][5]]\n",
    "    griddiag[4] = [gridnorme[1][0], gridnorme[2][1], gridnorme[3][2], gridnorme[4][3], gridnorme[5][4], 0]\n",
    "    griddiag[5] = [gridnorme[2][0], gridnorme[2][1], gridnorme[2][2], gridnorme[2][3], 0, 0]\n",
    "    return ligneWin(griddiag)\n",
    "\n",
    "\n",
    "def diagRigthToLeftWin(gridnorme):\n",
    "    griddiag = np.zeros(shape=(7, 6))\n",
    "    griddiag[0] = [gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3], 0, 0]\n",
    "    griddiag[1] = [gridnorme[4][0], gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3], 0]\n",
    "    griddiag[2] = [gridnorme[5][0], gridnorme[4][0], gridnorme[3][0], gridnorme[2][1], gridnorme[1][2], gridnorme[0][3]]\n",
    "    griddiag[3] = [gridnorme[5][1], gridnorme[4][2], gridnorme[3][3], gridnorme[2][4], gridnorme[1][5], gridnorme[0][6]]\n",
    "    griddiag[4] = [gridnorme[4][1], gridnorme[3][2], gridnorme[2][3], gridnorme[1][4], gridnorme[0][5], 0]\n",
    "    griddiag[5] = [gridnorme[3][1], gridnorme[2][2], gridnorme[1][3], gridnorme[0][4], 0, 0]\n",
    "\n",
    "    return ligneWin(griddiag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "memory = deque()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "maxWin = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9uVe3O-jKOlu"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2wWGSASDKOlu"
   },
   "outputs": [],
   "source": [
    "def localtest():  \n",
    "  global gridnorme, colred, epoch, memory, winner,maxWin\n",
    "  print(\"test ok: max=\", maxWin)\n",
    "  blueWinner = 0\n",
    "  redWinner = 0\n",
    "  equality = 0\n",
    "  # with torch.no_grad():\n",
    "  def playerCol():\n",
    "      bestcol = random.randrange(7)\n",
    "      j = 0\n",
    "      while colonnepleine(gridnorme, bestcol) and sum(\n",
    "              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "          j = (j + 1) % 7\n",
    "          bestcol = random.randrange(7)\n",
    "      grid = gridnorme.transpose().copy()\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, -1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      i = 0\n",
    "      for colon in grid:\n",
    "          if contains([-1, -1, -1, 0], colon.tolist()):\n",
    "              bestcol = i\n",
    "          i += 1\n",
    "      return bestcol;\n",
    "  \n",
    "  def playerRandom():\n",
    "      \n",
    "      bestcol = random.randrange(7)\n",
    "      j = 0\n",
    "      while colonnepleine(gridnorme, bestcol) and sum(\n",
    "              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "          j = (j + 1) % 7\n",
    "          bestcol = random.randrange(7)\n",
    "      return bestcol;\n",
    "\n",
    "  for p in range(0, 100):\n",
    "      first = False\n",
    "      gridnorme = np.zeros(shape=(6, 7))\n",
    "\n",
    "      for i in range(0, 42):\n",
    "\n",
    "          if first:\n",
    "\n",
    "              if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                      diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "                      \n",
    "                  actions = mcts.run(gridnorme, 1)\n",
    "                  # root = MonteCarloTreeSearchNode(state=gridnorme)\n",
    "                  # selected_node = root.best_action()\n",
    "                  actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                          dtype=torch.float32)\n",
    "                  actions /= torch.sum(actions)\n",
    "\n",
    "                  colonnes = torch.sort(actions, descending=True)\n",
    "                  action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                  colonne = action2rotation[colonnes.indices[0]]\n",
    "                  j = 0\n",
    "                  while colonnepleine(gridnorme, colonne) and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      j = (j + 1) % len(colonnes.indices)\n",
    "                      colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                  colonne = action2rotation[colonne]\n",
    "                  lign = 0\n",
    "                  while gridnorme[lign][colonne] != 0 and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      lign = (lign + 1) % 6\n",
    "                  gridnorme[lign][colonne] = 1\n",
    "                  first = not first\n",
    "              else:\n",
    "                  break\n",
    "          else:\n",
    "\n",
    "              if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                      diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "                  actions = mcts_iter.run(gridnorme, -1)\n",
    "                  # root = MonteCarloTreeSearchNode(state=gridnorme)\n",
    "                  # selected_node = root.best_action()\n",
    "                  actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                          dtype=torch.float32)\n",
    "                  actions /= torch.sum(actions)\n",
    "\n",
    "                  colonnes = torch.sort(actions, descending=True)\n",
    "                  action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                  colonne = action2rotation[colonnes.indices[0]]\n",
    "                  j = 0\n",
    "                  while colonnepleine(gridnorme, colonne) and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      j = (j + 1) % len(colonnes.indices)\n",
    "                      colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                  colonne = action2rotation[colonne]\n",
    "                  lign = 0\n",
    "                  while gridnorme[lign][colonne] != 0 and sum(\n",
    "                          (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                      lign = (lign + 1) % 6\n",
    "                  gridnorme[lign][colonne] = -1\n",
    "                  first = not first\n",
    "              else:\n",
    "                  break\n",
    "        \n",
    "\n",
    "      if winner == 1:\n",
    "        blueWinner += 1\n",
    "        winner = 0\n",
    "      elif winner == -1:\n",
    "        winner = 0\n",
    "        redWinner += 1\n",
    "      else:\n",
    "        equality += 1\n",
    "\n",
    "\n",
    "    \n",
    "       \n",
    "\n",
    "  return blueWinner, redWinner, equality\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ojVcbLdhyqCP"
   },
   "outputs": [],
   "source": [
    "def moyenne_glissante(valeurs, intervalle):\n",
    "    indice_debut = (intervalle - 1) // 2\n",
    "    liste_moyennes = [sum(valeurs[i - indice_debut:i + indice_debut + 1]) / intervalle for i in range(indice_debut, len(valeurs) - indice_debut)]\n",
    "    return liste_moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tLQTyqaf-EG9"
   },
   "outputs": [],
   "source": [
    "class AlphaLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_value, value, y_policy, policy):\n",
    "        value_error = (value - y_value) ** 2\n",
    "        policy_error = torch.sum((-policy *\n",
    "                                  (1e-8 + y_policy.float()).float().log()), 1)\n",
    "        total_error = (value_error.view(-1).float() + policy_error).mean()\n",
    "        return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PwtFhU9byqCc",
    "outputId": "dbbd6542-dca0-489b-a0fd-2d49853c9b7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "alphaloss = AlphaLoss()\n",
    "BATCH_SIZE=64\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.figure()\n",
    "from IPython.display import clear_output\n",
    "moyenneWinBlue=[]\n",
    "runningloss = []\n",
    "acurracy=[]\n",
    "def localtrain():\n",
    "    global maxWin,moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(0, 20):\n",
    "\n",
    "\n",
    "      batch_idx = 0\n",
    "      \n",
    "      pi_losses = []\n",
    "      v_losses = []\n",
    "\n",
    "      while batch_idx < int(len(memory) / BATCH_SIZE):\n",
    "\n",
    "        sample_ids = np.random.randint(0, len(memory), BATCH_SIZE)\n",
    "        boards, pis, vs = list(zip(*[(memory[i]) for i in sample_ids]))\n",
    "        gridnormeOne = np.zeros(shape=(6, 7))\n",
    "        gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "        gridnormeZero = np.zeros(shape=(6, 7))\n",
    "        boards = torch.FloatTensor(boards).cuda()\n",
    "\n",
    "        boardsAll=[]\n",
    "        for board in boards:\n",
    "            convert_zero(board,gridnormeZero)\n",
    "            convert_one(board, gridnormeOne)\n",
    "            convert_neg_one(board, gridnormenegOne)\n",
    "            gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "            last_signal = torch.FloatTensor(gridAll).cuda()\n",
    "            last_signal = last_signal.reshape(3, 6, 7)\n",
    "            boardsAll.append(last_signal)\n",
    "        pisAll = []\n",
    "        for policy in pis:\n",
    "            policy = torch.tensor(policy, dtype=torch.float32).cuda()\n",
    "            pisAll.append(policy)\n",
    "        vsAll = []\n",
    "        for value in vs:\n",
    "            value = torch.tensor(value, dtype=torch.float32).cuda()\n",
    "            vsAll.append(value)\n",
    "\n",
    "        statesignal = torch.FloatTensor([t.detach().cpu().numpy() for t in boardsAll]).cuda()\n",
    "\n",
    "        target_pis =torch.FloatTensor([t.cpu().numpy() for t in pisAll]).cuda()\n",
    "        target_vs = torch.FloatTensor(vsAll).cuda().reshape(BATCH_SIZE,1)\n",
    "          \n",
    "          \n",
    "        \n",
    "        out_pi, out_v = cnn(statesignal)\n",
    "        total_error=alphaloss(out_v,target_vs,out_pi,target_pis)\n",
    "        optimizer.zero_grad()\n",
    "        pi_losses.append(float(total_error))\n",
    "        total_error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_idx += 1\n",
    "    print('Policy Loss:{:.2f}'.format(np.mean(pi_losses)))\n",
    "    \n",
    "    \n",
    "    runningloss.append(np.mean(pi_losses))        \n",
    "    \n",
    "    clear_output(wait=True)     \n",
    "    pal = sns.dark_palette('purple',2)\n",
    "    ax = sns.lineplot(data=runningloss,palette=pal, color='red',  alpha=.5, linewidth=2)\n",
    "    ax.legend(['loss'])\n",
    "    # Customise some display properties\n",
    "    ax.set_title('winblueloss')\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set(ylim=(0, max(runningloss)))\n",
    "    # Ask Matplotlib to show it\n",
    "    plt.show()\n",
    "    savebraintrain()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nxSE6qe5KOlv"
   },
   "outputs": [],
   "source": [
    "def local(num_game):\n",
    "    \n",
    "\n",
    "    global gridnorme, colred, epoch, memory, history, n_steps, maxWin\n",
    "    \n",
    "\n",
    "    interval = []\n",
    "\n",
    "    \n",
    "    for h in range(0, num_game):\n",
    "        start_time = time.time()\n",
    "        n_steps = []\n",
    "        gridnorme = np.zeros(shape=(6, 7))\n",
    "        first = random.choice([True, False])\n",
    "        \n",
    "        for i in range(0, 42):\n",
    "            \n",
    "\n",
    "           \n",
    "\n",
    "            if first:\n",
    "                \n",
    "\n",
    "                if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                        diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "\n",
    "                      actions = mcts.run(gridnorme, -1)\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32).cuda()\n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = -1\n",
    "                      first = not first\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                if not (colWin(gridnorme)) and not (ligneWin(gridnorme)) and not (\n",
    "                        diagRigthToLeftWin(gridnorme)) and not (diagLeftToRightWin(gridnorme)):\n",
    "\n",
    "                      \n",
    "                      \n",
    "\n",
    "                      actions = mcts.run(gridnorme, 1)\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32).cuda()\n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = 1\n",
    "                      first = not first\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        n_steps.append([deepcopy(gridnorme), [0, 0, 0, 0, 0, 0, 0], 0])\n",
    "        if winner == 1:\n",
    "\n",
    "            reward=-1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "        elif winner == -1:\n",
    "\n",
    "            reward = 1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "\n",
    "\n",
    "        else:\n",
    "            for rew in range(0, len(n_steps)):\n",
    "                n_steps[rew][2] = 0\n",
    "\n",
    "        memory.extend(n_steps)\n",
    "\n",
    "        n_steps = []\n",
    "\n",
    "        \n",
    "            \n",
    "        interval.append(time.time() - start_time)\n",
    "        if h > 5:\n",
    "            localtrain()\n",
    "        print('Total time in seconde:{:.2f}  '.format(np.mean(interval)),' ',h)\n",
    "        if h%10==0:\n",
    "          savebrain1()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TqenSZ-hKOlw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import csv\n",
    "def savebrain1():\n",
    "    global savefile\n",
    "    global cnn, optimizer, cnnred\n",
    "    \n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    checkpoint = {'model': cnn,\n",
    "                  'state_dict': cnn.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, 'bestrandom.pth')\n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    \n",
    "def savebraintrain():\n",
    "    global savefile\n",
    "    global runningloss\n",
    "    \n",
    "\n",
    "    with open('loss_2000.csv', mode='w') as loss_file:\n",
    "        blue_writer = csv.writer(loss_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        blue_writer.writerow(runningloss)\n",
    "\n",
    "    print(\"=> saving moyenne... \",runningloss[len(runningloss)-1])\n",
    "        \n",
    "def loadbrain2():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('best_iter200.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "        checkpoint = torch.load('best_iter200.pth', map_location=cuda0)\n",
    "        cnn_iter1.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "        \n",
    "def loadcsv():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred,runningloss\n",
    "    \n",
    "    if os.path.isfile('loss_2000.csv'):\n",
    "\n",
    "        with open('loss_2000.csv', newline='') as f:\n",
    "            reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "            runningloss = list(reader)[0]\n",
    "\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "\n",
    "def loadbrain1():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('bestrandom.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "        checkpoint = torch.load('bestrandom.pth', map_location=cuda0)\n",
    "        cnn.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "      \n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YqafRVhUMnF",
    "outputId": "958f3e22-0d52-491b-ea89-94e1e3f04282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint... \n",
      "=> loading checkpoint... \n",
      "done !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loadcsv()\n",
    "\n",
    "loadbrain1()\n",
    "#loadbrain2()\n",
    "# savebrain1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "d6BmGH9pyqCg",
    "outputId": "3dfca9ef-bc68-4aba-9efa-b65c17e7711e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving moyenne...  1.131778018815177\n",
      "Total time in seconde:290.60     21\n",
      "simulation:776.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2f9bab158c80>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  policy = torch.tensor(policy, dtype=torch.float32).cuda()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ea997acf149a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ce3137fcdcc2>\u001b[0m in \u001b[0;36mlocal\u001b[0;34m(num_game)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mlocaltrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total time in seconde:{:.2f}  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-2f9bab158c80>\u001b[0m in \u001b[0;36mlocaltrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpi_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtotal_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "local(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RaHHwNF9jCD"
   },
   "outputs": [],
   "source": [
    "savebrain1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runningloss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Connect4_alpha_zero.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
