{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "Lglw-LkAKOle"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import torch\n",
    "\n",
    "import Bag as newGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "XGpK6EopYBLq"
   },
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "69X_-qPkKOlh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "global epoch\n",
    "epoch = 0\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('werkzeug')\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "BExJk30EKOli"
   },
   "outputs": [],
   "source": [
    "def get_next_state(board, player, action):\n",
    "    nextBoard = np.copy(board)\n",
    "    lign = 0\n",
    "    while nextBoard[lign][action] != 0 and sum(\n",
    "            (x != 0) for x in nextBoard.transpose().flatten()) < 42:\n",
    "        lign = (lign + 1) % 6\n",
    "    nextBoard[lign][action] = player\n",
    "\n",
    "    # Return the new game, but\n",
    "    # change the perspective of the game with negative\n",
    "    return nextBoard, -player\n",
    "\n",
    "\n",
    "def has_legal_moves(board):\n",
    "    for colonne in range(7):\n",
    "        if not colonnepleine(board, colonne) and sum(\n",
    "                (x != 0) for x in board.transpose().flatten()) < 42:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_valid_moves(board):\n",
    "    # All moves are invalid by default\n",
    "    game.setActionprob()\n",
    "    valid_moves=np.zeros(len(game.actionprob))\n",
    "    probscolor=[]\n",
    "    probsshape=[]\n",
    "\n",
    "    for index,i in enumerate(game.listValidMoves):\n",
    "        \n",
    "        if len(i)<2:\n",
    "            for tile in i:\n",
    "                probscolor.append([newGame.TileColor[tile.color],0,0,tile.coordinate.x,tile.coordinate.y])\n",
    "                probsshape.append([0,newGame.TileShape[tile.shape],0,tile.coordinate.x,tile.coordinate.y])\n",
    "\n",
    "        else:\n",
    "            if (i[0].coordinate.x-i[1].coordinate.x)>0:\n",
    "                for tile in i:\n",
    "                    probscolor.append([newGame.TileColor[tile.color],0,0,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                    probsshape.append([0,newGame.TileShape[tile.shape],0,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                break        \n",
    "            if (i[0].coordinate.x-i[1].coordinate.x)<0:\n",
    "                for tile in i:\n",
    "                    probscolor.append([newGame.TileColor[tile.color],0,1,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                    probsshape.append([0,newGame.TileShape[tile.shape],1,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                break    \n",
    "            if (i[0].coordinate.y-i[1].coordinate.y)>0:\n",
    "                for tile in i:\n",
    "                    probscolor.append([newGame.TileColor[tile.color],0,2,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                    probsshape.append([0,newGame.TileShape[tile.shape],2,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                break    \n",
    "            if (i[0].coordinate.y-i[1].coordinate.y)<0:\n",
    "                for tile in i:\n",
    "                    probscolor.append([newGame.TileColor[tile.color],0,3,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                    probsshape.append([0,newGame.TileShape[tile.shape],3,i[0].coordinate.x,i[0].coordinate.y])\n",
    "                break                            \n",
    "\n",
    "    for prob in probscolor:\n",
    "        valid_moves[game.actionprob.index([prob])]=1\n",
    "\n",
    "\n",
    "    for prob in probsshape:\n",
    "        valid_moves[game.actionprob.index([prob])]=1    \n",
    "         \n",
    "    \n",
    "\n",
    "    return valid_moves\n",
    "\n",
    "\n",
    "def get_reward_for_player(board, player):\n",
    "    # return None if not ended, 1 if player 1 wins, -1 if player 1 lost\n",
    "\n",
    "    if colWin(board) or ligneWin(board) or diagRigthToLeftWin(board) or diagLeftToRightWin(board):\n",
    "        if winner == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    # if has_legal_moves(board):\n",
    "    #     return None\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_canonical_board(board, player):\n",
    "    return player * board\n",
    "\n",
    "\n",
    "def ucb_score(parent, child):\n",
    "    \"\"\"\n",
    "    The score for an action that would transition between the parent and child.\n",
    "    \"\"\"\n",
    "    prior_score = child.prior * math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
    "    if (child.visit_count > 0) and (child.prior > 0):\n",
    "        # The value of the child is from the perspective of the opposing player\n",
    "        value_score = -child.value()\n",
    "    else:\n",
    "        value_score = 0\n",
    "\n",
    "    return value_score + prior_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "i5IcroHfKOlk"
   },
   "outputs": [],
   "source": [
    "def add_dirichlet_noise(child_priors):\n",
    "        dirichlet_input = [0.1 for x in range(len(child_priors))]\n",
    "        dirichlet_list = np.random.dirichlet(dirichlet_input)\n",
    "        noisy_psa_vector = []\n",
    "        for idx, psa in enumerate(child_priors):\n",
    "            noisy_psa_vector.append(\n",
    "                (1 - 0.25) * psa + 0.25 * dirichlet_list[idx])\n",
    "        child_priors =noisy_psa_vector[0]\n",
    "\n",
    "\n",
    "        return (child_priors)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "-61Hi3drKOlk"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, prior, to_play):\n",
    "        self.visit_count = 0\n",
    "        self.to_play = to_play\n",
    "        self.prior = prior\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.state = None\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def select_child(self):\n",
    "        \"\"\"\n",
    "        Select the child with the highest UCB score.\n",
    "        \"\"\"\n",
    "        best_score = -np.inf\n",
    "        best_action = -1\n",
    "        best_child = None\n",
    "\n",
    "        for action, child in self.children.items():\n",
    "            score = ucb_score(self, child)\n",
    "            if not colonnepleine(self.state, action):\n",
    "                if score> best_score:\n",
    "                    best_score = score\n",
    "                    best_action = action\n",
    "                    best_child = child\n",
    "\n",
    "        return best_action, best_child\n",
    "\n",
    "    def expand(self, state, to_play, action_probs):\n",
    "        \"\"\"\n",
    "        We expand a node and keep track of the prior policy probability given by neural network choice 5 first\n",
    "        \"\"\"\n",
    "        self.to_play = to_play\n",
    "        self.state = state\n",
    "        for i in range(len(action_probs)):\n",
    "          if action_probs[i].data in torch.topk(action_probs, 5).values and actionCouldWin(self.state, action_probs[i]):\n",
    "            self.children[i] = Node(prior=action_probs[0][i].item(), to_play=self.to_play * -1)\n",
    "          else:\n",
    "            self.children[i] = Node(prior=0, to_play=self.to_play * -1)\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Debugger pretty print node info\n",
    "        \"\"\"\n",
    "        prior = \"{0:.2f}\".format(self.prior)\n",
    "        return \"{} Prior: {} Count: {} Value: {}\".format(self.state.__str__(), prior, self.visit_count, self.value())\n",
    "                                                         \n",
    "class MCTS:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "        #   gridnormeOne = np.zeros(shape=(26,54,54))\n",
    "        #   gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "        #   gridnormeZero = np.zeros(shape=(6, 7))\n",
    "          root = Node(0, to_play)\n",
    "        #   convert_zero(state, gridnormeZero)\n",
    "        #   convert_one(state, gridnormeOne)\n",
    "        #   convert_neg_one(state, gridnormenegOne)\n",
    "          gridAll = state\n",
    "          #statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32)\n",
    "          action_probs, value = cnn(statesignal)\n",
    "          \n",
    "          \n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          #action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()\n",
    "          action_probs = action_probs * torch.tensor(valid_moves, dtype=torch.float32)  # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          #for i in range(777):\n",
    "          for i in range(5):    \n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  \n",
    "                  gridAll = next_state\n",
    "                  #statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32)\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  #action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda()\n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32)  # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root\n",
    "\n",
    "class MCTS_iter:\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1\n",
    "\n",
    "    def run(self, state, to_play):\n",
    "      with torch.no_grad():      \n",
    "          gridnormeOne = np.zeros(shape=(26,54,54))\n",
    "          \n",
    "          root = Node(0, to_play)\n",
    "          \n",
    "          #statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "          statesignal = torch.tensor([gridAll], dtype=torch.float32)\n",
    "\n",
    "          action_probs, value = cnn_iter1(statesignal)\n",
    "\n",
    "          valid_moves = get_valid_moves(state)\n",
    "\n",
    "          #action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda() \n",
    "          action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32) # mask invalid moves\n",
    "          action_probs /= torch.sum(action_probs)\n",
    "          action_probs = add_dirichlet_noise(action_probs)\n",
    "          root.expand(state, to_play, action_probs)\n",
    "\n",
    "          for i in range(777):\n",
    "              \n",
    "              node = root\n",
    "              search_path = [node]\n",
    "              print('\\rsimulation:{:.2f}'.format(i),end='')\n",
    "\n",
    "              # SELECT\n",
    "              while node.expanded():\n",
    "                  action, node = node.select_child()\n",
    "                  search_path.append(node)\n",
    "\n",
    "              parent = search_path[-2]\n",
    "              state = parent.state\n",
    "              # Now we're at a leaf node and we would like to expand\n",
    "              # Players always play from their own perspective\n",
    "              next_state, _ = get_next_state(state, player=1, action=action)\n",
    "              # Get the board from the perspective of the other player\n",
    "              next_state = get_canonical_board(next_state, player=-1)\n",
    "\n",
    "              # The value of the new state from the perspective of the other player\n",
    "              value = get_reward_for_player(next_state, player=1)\n",
    "              if value==0 and has_legal_moves(next_state):\n",
    "                  # If the game has not ended:\n",
    "                  # EXPAND\n",
    "                  \n",
    "                  gridAll = next_state\n",
    "                  #statesignal = torch.tensor([gridAll], dtype=torch.float32).cuda()\n",
    "                  statesignal = torch.tensor([gridAll], dtype=torch.float32)\n",
    "\n",
    "                  statesignal = statesignal.reshape(3, 6, 7)\n",
    "                  \n",
    "                  action_probs, value = cnn_iter1(statesignal)\n",
    "                  valid_moves = get_valid_moves(next_state)\n",
    "                  #action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32).cuda() \n",
    "                  action_probs = action_probs * torch.tensor([valid_moves], dtype=torch.float32) # mask invalid moves\n",
    "                  action_probs /= torch.sum(action_probs)\n",
    "\n",
    "                  node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "              self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "          return root   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "    # Making the body\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = 7\n",
    "       # self.conv1 = nn.Conv2d(3, 1024, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn1 = nn.BatchNorm2d(1024).cuda()\n",
    "        #self.conv2 = nn.Conv2d(1024, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn2 = nn.BatchNorm2d(2048).cuda()\n",
    "        #self.conv3 = nn.Conv2d(2048, 4096, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn3 = nn.BatchNorm2d(4096).cuda()\n",
    "        #self.conv4 = nn.Conv2d(4096, 2048, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn4 = nn.BatchNorm2d(2048).cuda()\n",
    "        #self.conv5 = nn.Conv2d(2048, 512, kernel_size=4, stride=1, padding=1).cuda()\n",
    "        #self.bn5 = nn.BatchNorm2d(512).cuda()\n",
    "        self.conv1 = nn.Conv2d(26, 256, kernel_size=12, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "        self.conv2 = nn.Conv2d(256, 512, kernel_size=12, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(512)\n",
    "        #self.conv3 = nn.Conv2d(2048, 4096, kernel_size=4, stride=1, padding=1)\n",
    "        #self.bn3 = nn.BatchNorm2d(4096)\n",
    "        #self.conv4 = nn.Conv2d(4096, 2048, kernel_size=4, stride=1, padding=1)\n",
    "        #self.bn4 = nn.BatchNorm2d(2048)\n",
    "        #self.conv5 = nn.Conv2d(2048, 512, kernel_size=4, stride=1, padding=1)\n",
    "        #self.bn5 = nn.BatchNorm2d(512)\n",
    "\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.view(-1,26, 54, 54)  # batch_size x channels x board_x x board_y\n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        s = F.relu(self.bn2(self.conv2(s)))\n",
    "        #s = F.relu(self.bn3(self.conv3(s)))\n",
    "        #s = F.relu(self.bn4(self.conv4(s)))\n",
    "        #s = F.relu(self.bn5(self.conv5(s)))\n",
    "\n",
    "        return s\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=512, planes=512, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "        #                       padding=1, bias=False).cuda()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        #self.bn1 = nn.BatchNorm2d(planes).cuda()\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        #self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "        #                       padding=1, bias=False).cuda()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        #self.bn2 = nn.BatchNorm2d(planes).cuda()\n",
    "        #self.drp = nn.Dropout(0.3).cuda()\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.drp = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.drp(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.bn2(out))\n",
    "        out = self.drp(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    # shape=6*7*32\n",
    "    shape = 663552\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.shape,512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.drp = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(512, 460800)\n",
    "\n",
    "    def forward(self, s):\n",
    "        v = s.view(-1, self.shape)  # batch_size X channel X height X width\n",
    "        v = self.drp(F.relu(self.fc1(v)))\n",
    "        v = torch.tanh(self.fc2(v))\n",
    "\n",
    "\n",
    "        p = s.view(-1, self.shape)\n",
    "        p = self.drp(F.relu(self.fc1(p)))\n",
    "        p = self.fc(p)\n",
    "        p = self.logsoftmax(p).exp()\n",
    "        return p, v\n",
    "\n",
    "\n",
    "class ConnectNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConnectNet, self).__init__()\n",
    "        #self.conv = ConvBlock().cuda()\n",
    "        self.conv = ConvBlock()\n",
    "        for block in range(30):\n",
    "            #setattr(self, \"res_%i\" % block, ResBlock().cuda())\n",
    "            setattr(self, \"res_%i\" % block, ResBlock())\n",
    "        self.outblock = OutBlock()\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(30):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights of layers using Kaiming Normal (He et al.) as argument of \"Apply\" function of\n",
    "        \"nn.Module\"\n",
    "        :param m: Layer to initialize\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if isinstance(self.conv.conv1, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv1.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv1.bias)\n",
    "        if isinstance(self.conv.bn1, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn1.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn1.bias.data, 0)\n",
    "        if isinstance(self.conv.conv2, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(self.conv.conv2.weight)\n",
    "            torch.nn.init.zeros_(self.conv.conv2.bias)\n",
    "        if isinstance(self.conv.bn2, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(self.conv.bn2.weight.data, mean=1, std=0.02)\n",
    "            torch.nn.init.constant_(self.conv.bn2.bias.data, 0)\n",
    "        # if isinstance(self.conv.conv3, nn.Conv2d):\n",
    "        #     torch.nn.init.xavier_uniform_(self.conv.conv3.weight)\n",
    "        #     torch.nn.init.zeros_(self.conv.conv3.bias)\n",
    "        # if isinstance(self.conv.bn3, nn.BatchNorm2d):\n",
    "        #     torch.nn.init.normal_(self.conv.bn3.weight.data, mean=1, std=0.02)\n",
    "        #     torch.nn.init.constant_(self.conv.bn3.bias.data, 0)\n",
    "        # if isinstance(self.conv.conv4, nn.Conv2d):\n",
    "        #     torch.nn.init.xavier_uniform_(self.conv.conv4.weight)\n",
    "        #     torch.nn.init.zeros_(self.conv.conv4.bias)\n",
    "        # if isinstance(self.conv.bn4, nn.BatchNorm2d):\n",
    "        #     torch.nn.init.normal_(self.conv.bn4.weight.data, mean=1, std=0.02)\n",
    "        #     torch.nn.init.constant_(self.conv.bn4.bias.data, 0)\n",
    "        # if isinstance(self.conv.conv5, nn.Conv2d):\n",
    "        #     torch.nn.init.xavier_uniform_(self.conv.conv5.weight)\n",
    "        #     torch.nn.init.zeros_(self.conv.conv5.bias)\n",
    "        # if isinstance(self.conv.bn5, nn.BatchNorm2d):\n",
    "        #     torch.nn.init.normal_(self.conv.bn5.weight.data, mean=1, std=0.02)\n",
    "        #     torch.nn.init.constant_(self.conv.bn5.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "VjlWf12-KOlt"
   },
   "outputs": [],
   "source": [
    "#cnn = ConnectNet().to(cuda0)\n",
    "cnn = ConnectNet()\n",
    "cnn.init_weights()\n",
    "#cnn_iter1 = ConnectNet().to(cuda0)\n",
    "cnn_iter1 = ConnectNet()\n",
    "cnn_iter1.init_weights()\n",
    "n_step = 0\n",
    "\n",
    "Step = namedtuple('Step', ['state', 'action', 'reward'])\n",
    "from dataclasses import dataclass\n",
    "\n",
    "mcts = MCTS()\n",
    "mcts_iter=MCTS_iter()\n",
    "@dataclass\n",
    "class Step:\n",
    "    state: []\n",
    "    action: []\n",
    "    reward: int = 0\n",
    "\n",
    "\n",
    "global memory\n",
    "\n",
    "global rewards\n",
    "rewards = []\n",
    "\n",
    "lossreward = nn.MSELoss()\n",
    "# lossreward = nn.BCEWithLogitsLoss()\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.SGD(cnn.parameters(),lr=0.01,momentum=0.9,weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0000001)\n",
    "reward = 0.0\n",
    "global gridnorme\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def treeSearch(batch):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    values = []\n",
    "    for series in batch:\n",
    "        inputs.append(series.state)\n",
    "        targets.append(series.action)\n",
    "        values.append(series.reward)\n",
    "    return torch.tensor([t.numpy() for t in inputs], dtype=torch.float), torch.tensor([t.numpy() for t in targets],\n",
    "                                                                                      dtype=torch.float), torch.tensor(\n",
    "        [t.numpy() for t in values], dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_batch(batch_size):  # creates an iterator that returns random batches\n",
    "    ofs = 0\n",
    "    vals = list(memory)\n",
    "    np.random.shuffle(vals)\n",
    "    while (ofs + 1) * batch_size <= len(memory):\n",
    "        yield vals[ofs * batch_size:(ofs + 1) * batch_size]\n",
    "        ofs += 1\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "def contains(subseq, inseq):\n",
    "    return any(inseq[pos:pos + len(subseq)] == subseq for pos in range(0, len(inseq) - len(subseq) + 1))\n",
    "\n",
    "\n",
    "winner = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def isFinish(gridnorme):\n",
    "    matrix =np.array(gridnorme)\n",
    "# Count occurrence of element '3' in each column\n",
    "    count = np.count_nonzero(matrix == 1)\n",
    "    return count==108\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "memory = deque()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "maxWin = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "9uVe3O-jKOlu"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "ojVcbLdhyqCP"
   },
   "outputs": [],
   "source": [
    "def moyenne_glissante(valeurs, intervalle):\n",
    "    indice_debut = (intervalle - 1) // 2\n",
    "    liste_moyennes = [sum(valeurs[i - indice_debut:i + indice_debut + 1]) / intervalle for i in range(indice_debut, len(valeurs) - indice_debut)]\n",
    "    return liste_moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "tLQTyqaf-EG9"
   },
   "outputs": [],
   "source": [
    "class AlphaLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_value, value, y_policy, policy):\n",
    "        value_error = (value - y_value) ** 2\n",
    "        policy_error = torch.sum((-policy *\n",
    "                                  (1e-8 + y_policy.float()).float().log()), 1)\n",
    "        total_error = (value_error.view(-1).float() + policy_error).mean()\n",
    "        return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PwtFhU9byqCc",
    "outputId": "dbbd6542-dca0-489b-a0fd-2d49853c9b7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "alphaloss = AlphaLoss()\n",
    "BATCH_SIZE=64\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.figure()\n",
    "from IPython.display import clear_output\n",
    "moyenneWinBlue=[]\n",
    "runningloss = []\n",
    "acurracy=[]\n",
    "def localtrain():\n",
    "    global maxWin,moyenneWinBlue,BATCH_SIZE,pi_losses,v_losses,acurracy,runningloss\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(0, 20):\n",
    "\n",
    "\n",
    "      batch_idx = 0\n",
    "      \n",
    "      pi_losses = []\n",
    "      v_losses = []\n",
    "\n",
    "      while batch_idx < int(len(memory) / BATCH_SIZE):\n",
    "\n",
    "        sample_ids = np.random.randint(0, len(memory), BATCH_SIZE)\n",
    "        boards, pis, vs = list(zip(*[(memory[i]) for i in sample_ids]))\n",
    "        gridnormeOne = np.zeros(shape=(6, 7))\n",
    "        gridnormenegOne = np.zeros(shape=(6, 7))\n",
    "        gridnormeZero = np.zeros(shape=(6, 7))\n",
    "        boards = torch.FloatTensor(boards).cuda()\n",
    "\n",
    "        boardsAll=[]\n",
    "        for board in boards:\n",
    "          \n",
    "            gridAll = [gridnormeZero, gridnormeOne, gridnormenegOne]\n",
    "            last_signal = torch.FloatTensor(gridAll).cuda()\n",
    "            last_signal = last_signal.reshape(3, 6, 7)\n",
    "            boardsAll.append(last_signal)\n",
    "        pisAll = []\n",
    "        for policy in pis:\n",
    "            policy = torch.tensor(policy, dtype=torch.float32).cuda()\n",
    "            pisAll.append(policy)\n",
    "        vsAll = []\n",
    "        for value in vs:\n",
    "            value = torch.tensor(value, dtype=torch.float32).cuda()\n",
    "            vsAll.append(value)\n",
    "\n",
    "        statesignal = torch.FloatTensor([t.detach().cpu().numpy() for t in boardsAll]).cuda()\n",
    "\n",
    "        target_pis =torch.FloatTensor([t.cpu().numpy() for t in pisAll]).cuda()\n",
    "        target_vs = torch.FloatTensor(vsAll).cuda().reshape(BATCH_SIZE,1)\n",
    "          \n",
    "          \n",
    "        \n",
    "        out_pi, out_v = cnn(statesignal)\n",
    "        total_error=alphaloss(out_v,target_vs,out_pi,target_pis)\n",
    "        optimizer.zero_grad()\n",
    "        pi_losses.append(float(total_error))\n",
    "        total_error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_idx += 1\n",
    "    print('Policy Loss:{:.2f}'.format(np.mean(pi_losses)))\n",
    "    \n",
    "    \n",
    "    runningloss.append(np.mean(pi_losses))        \n",
    "    \n",
    "    clear_output(wait=True)     \n",
    "    pal = sns.dark_palette('purple',2)\n",
    "    ax = sns.lineplot(data=runningloss,palette=pal, color='red',  alpha=.5, linewidth=2)\n",
    "    ax.legend(['loss'])\n",
    "    # Customise some display properties\n",
    "    ax.set_title('winblueloss')\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set(ylim=(0, max(runningloss)))\n",
    "    # Ask Matplotlib to show it\n",
    "    plt.show()\n",
    "    savebraintrain()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "nxSE6qe5KOlv"
   },
   "outputs": [],
   "source": [
    "def local(num_game):\n",
    "    \n",
    "\n",
    "    global gridnorme, game, epoch, memory, history, n_steps, maxWin\n",
    "    \n",
    "\n",
    "    interval = []\n",
    "\n",
    "    \n",
    "    for h in range(0, num_game):\n",
    "        start_time = time.time()\n",
    "        n_steps = []\n",
    "        gridnorme = np.zeros(shape=(26,54, 54))\n",
    "        game=newGame.Game()\n",
    "        \n",
    "        \n",
    "        first = random.choice([True, False])\n",
    "        \n",
    "        for i in range(0,54):\n",
    "            \n",
    "\n",
    "           \n",
    "\n",
    "            if first:\n",
    "                \n",
    "\n",
    "                if not isFinish(gridnorme):\n",
    "                    \n",
    "                      game.permutePlayer1()  \n",
    "                      actions = mcts.run(gridnorme, -1)\n",
    "                      #actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                      #                        dtype=torch.float32).cuda()\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32)\n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = -1\n",
    "                      first = not first\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                if not isFinish(gridnorme):\n",
    "\n",
    "                      \n",
    "                      \n",
    "                      game.permutePlayer2()  \n",
    "                      actions = mcts.run(gridnorme, 1)\n",
    "                      #actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                      #                        dtype=torch.float32).cuda()\n",
    "                      actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\n",
    "                                              dtype=torch.float32)                     \n",
    "                      actions /= torch.sum(actions)\n",
    "                      colonnes = torch.sort(actions, descending=True)\n",
    "                      action2rotation = [0, 1, 2, 3, 4, 5, 6]\n",
    "                      colonne = action2rotation[colonnes.indices[0]]\n",
    "                      j = 0\n",
    "                      while colonnepleine(gridnorme, colonne) and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          j = (j + 1) % len(colonnes.indices)\n",
    "                          colonne = action2rotation[colonnes.indices[j]]\n",
    "\n",
    "                      colonne = action2rotation[colonne]\n",
    "                      lign = 0\n",
    "                      while gridnorme[lign][colonne] != 0 and sum(\n",
    "                              (x != 0) for x in gridnorme.transpose().flatten()) < 42:\n",
    "                          lign = (lign + 1) % 6\n",
    "\n",
    "                      n_steps.append([deepcopy(gridnorme), actions, 0])\n",
    "                      gridnorme[lign][colonne] = 1\n",
    "                      first = not first\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        n_steps.append([deepcopy(gridnorme), [0, 0, 0, 0, 0, 0, 0], 0])\n",
    "        if winner == 1:\n",
    "\n",
    "            reward=-1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "        elif winner == -1:\n",
    "\n",
    "            reward = 1\n",
    "            for rew in range(len(n_steps) - 1, 0, -1):\n",
    "                n_steps[rew][2] = reward\n",
    "                reward=-reward\n",
    "\n",
    "\n",
    "        else:\n",
    "            for rew in range(0, len(n_steps)):\n",
    "                n_steps[rew][2] = 0\n",
    "\n",
    "        memory.extend(n_steps)\n",
    "\n",
    "        n_steps = []\n",
    "\n",
    "        \n",
    "            \n",
    "        interval.append(time.time() - start_time)\n",
    "        if h > 5:\n",
    "            localtrain()\n",
    "        print('Total time in seconde:{:.2f}  '.format(np.mean(interval)),' ',h)\n",
    "        if h%10==0:\n",
    "          savebrain1()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "TqenSZ-hKOlw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import csv\n",
    "def savebrain1():\n",
    "    global savefile\n",
    "    global cnn, optimizer, cnnred\n",
    "    \n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    checkpoint = {'model': cnn,\n",
    "                  'state_dict': cnn.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, 'bestrandom.pth')\n",
    "\n",
    "    print(\"=> saving checkpoint... \")\n",
    "    \n",
    "def savebraintrain():\n",
    "    global savefile\n",
    "    global runningloss\n",
    "    \n",
    "\n",
    "    with open('loss_2000.csv', mode='w') as loss_file:\n",
    "        blue_writer = csv.writer(loss_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        blue_writer.writerow(runningloss)\n",
    "\n",
    "    print(\"=> saving moyenne... \",runningloss[len(runningloss)-1])\n",
    "        \n",
    "def loadbrain2():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('best_iter200.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "        checkpoint = torch.load('best_iter200.pth', map_location=cuda0)\n",
    "        cnn_iter1.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "        \n",
    "def loadcsv():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred,runningloss\n",
    "    \n",
    "    if os.path.isfile('loss_2000.csv'):\n",
    "\n",
    "        with open('loss_2000.csv', newline='') as f:\n",
    "            reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "            runningloss = list(reader)[0]\n",
    "\n",
    "        print(\"=> loading checkpoint... \")\n",
    "       \n",
    "\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")\n",
    "\n",
    "def loadbrain1():\n",
    "    global cnn, optimizer, rewardcnn, cnnred, rewardcnnred\n",
    "    if os.path.isfile('bestrandom.pth'):\n",
    "        print(\"=> loading checkpoint... \")\n",
    "        checkpoint = torch.load('bestrandom.pth', map_location=cuda0)\n",
    "        cnn.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "      \n",
    "        \n",
    "       \n",
    "\n",
    "        print(\"done !\")\n",
    "    else:\n",
    "        print(\"no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actionCouldWin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000014?line=0'>1</a>\u001b[0m local(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb Cell 13'\u001b[0m in \u001b[0;36mlocal\u001b[0;34m(num_game)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isFinish(gridnorme):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=28'>29</a>\u001b[0m       game\u001b[39m.\u001b[39mpermutePlayer1()  \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=29'>30</a>\u001b[0m       actions \u001b[39m=\u001b[39m mcts\u001b[39m.\u001b[39;49mrun(gridnorme, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=30'>31</a>\u001b[0m       \u001b[39m#actions = torch.tensor([actions.children[visit].visit_count for visit in actions.children],\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=31'>32</a>\u001b[0m       \u001b[39m#                        dtype=torch.float32).cuda()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=32'>33</a>\u001b[0m       actions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([actions\u001b[39m.\u001b[39mchildren[visit]\u001b[39m.\u001b[39mvisit_count \u001b[39mfor\u001b[39;00m visit \u001b[39min\u001b[39;00m actions\u001b[39m.\u001b[39mchildren],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000012?line=33'>34</a>\u001b[0m                               dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;32m/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb Cell 6'\u001b[0m in \u001b[0;36mMCTS.run\u001b[0;34m(self, state, to_play)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=87'>88</a>\u001b[0m action_probs \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(action_probs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=88'>89</a>\u001b[0m action_probs \u001b[39m=\u001b[39m add_dirichlet_noise(action_probs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=89'>90</a>\u001b[0m root\u001b[39m.\u001b[39;49mexpand(state, to_play, action_probs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=91'>92</a>\u001b[0m \u001b[39m#for i in range(777):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):    \n",
      "\u001b[1;32m/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb Cell 6'\u001b[0m in \u001b[0;36mNode.expand\u001b[0;34m(self, state, to_play, action_probs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=40'>41</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(action_probs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=42'>43</a>\u001b[0m   \u001b[39mif\u001b[39;00m action_probs[i]\u001b[39m.\u001b[39mdata \u001b[39min\u001b[39;00m torch\u001b[39m.\u001b[39mtopk(action_probs, \u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mvalues \u001b[39mand\u001b[39;00m actionCouldWin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, action_probs[i]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=43'>44</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren[i] \u001b[39m=\u001b[39m Node(prior\u001b[39m=\u001b[39maction_probs[\u001b[39m0\u001b[39m][i]\u001b[39m.\u001b[39mitem(), to_play\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_play \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jcgouleau/jupyther-bonneton/alphazero/qwirckleAlphazero.ipynb#ch0000005?line=44'>45</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actionCouldWin' is not defined"
     ]
    }
   ],
   "source": [
    "local(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YqafRVhUMnF",
    "outputId": "958f3e22-0d52-491b-ea89-94e1e3f04282"
   },
   "outputs": [],
   "source": [
    "\n",
    "loadcsv()\n",
    "\n",
    "loadbrain1()\n",
    "#loadbrain2()\n",
    "# savebrain1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "d6BmGH9pyqCg",
    "outputId": "3dfca9ef-bc68-4aba-9efa-b65c17e7711e"
   },
   "outputs": [],
   "source": [
    "local(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RaHHwNF9jCD"
   },
   "outputs": [],
   "source": [
    "savebrain1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runningloss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Connect4_alpha_zero.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "hide_input": false,
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
